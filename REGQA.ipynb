{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if you get an error when connecting to pinecone, uncomment this block and run it first\n",
    "# !pip install -qU \\\n",
    "#     openai==0.27.7 \\\n",
    "#     \"pinecone-client[grpc]\"==2.2.1 \\\n",
    "#     datasets==2.12.0 \\\n",
    "#     tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pdf path and define query\n",
    "pdf_path = \"/Users/seeker/Desktop/AxeÃÅ Engineering/sample documents/APPLE_US_TERMS_COND-0056.pdf\"\n",
    "query = \"What is the supplier code of conduct?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import openai\n",
    "\n",
    "# authenticate with openai\n",
    "dotenv.load_dotenv(dotenv_path=\"./.env.local\")\n",
    "openai.api_key = os.environ[\"gpt_api_secret\"]\n",
    "\n",
    "# openai.Engine.list()  # check we have authenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seeker/Desktop/IST 664 - Natural Language Processing/REGQA_project/regqa/lib/python3.9/site-packages/pinecone/index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WhoAmIResponse(username='b42c5d9', user_label='default', projectname='4796d1f')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pinecone\n",
    "\n",
    "# initialize connection to pinecone\n",
    "api_key = os.environ[\"pinecone_api_key\"]\n",
    "env = \"us-west1-gcp-free\"\n",
    "\n",
    "pinecone.init(api_key=api_key, environment=env)\n",
    "pinecone.whoami()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to query the engine\n",
    "def complete(prompt):\n",
    "    # query text-davinci-003\n",
    "    res = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=400,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "    return res['choices'][0]['text'].strip()\n",
    "\n",
    "def retrieve(query):\n",
    "    res = openai.Embedding.create(\n",
    "        input=[query],\n",
    "        engine=embed_model\n",
    "    )\n",
    "\n",
    "    # retrieve from Pinecone\n",
    "    xq = res['data'][0]['embedding']\n",
    "                     \n",
    "    # get relevant contexts\n",
    "    res = index.query(xq, top_k=1, include_metadata=True)\n",
    "    context = res['matches'][0]['metadata']['text']\n",
    "\n",
    "    # build our prompt with the retrieved context\n",
    "    prompt_start = (\n",
    "        \"Answer the question based on the context below.\\n\\n\"+\n",
    "        \"context:\\n\"\n",
    "    )\n",
    "    prompt_end = (\n",
    "        f\"\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
    "    )\n",
    "    prompt = prompt_start + context + prompt_end\n",
    "    return prompt\n",
    "\n",
    "# function to extract tet from pdf\n",
    "import PyPDF2\n",
    "import nltk\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as pdf_file_obj:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file_obj)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page_obj = pdf_reader.pages[page_num]\n",
    "            text += page_obj.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract text from pdf\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "## convert text to knowledge base\n",
    "# split the text into chunks of 10000 characters \n",
    "# with an overlap of 300 characters\n",
    "chunks = []\n",
    "chunk_size = 10000\n",
    "overlap_size = 5000\n",
    "\n",
    "for i in range(0, len(text), chunk_size - overlap_size):\n",
    "    chunks.append(text[i:i + chunk_size])\n",
    "\n",
    "embed_model = \"text-embedding-ada-002\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=chunks,\n",
    "    engine=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create index\n",
    "index_name = \"regqa\"\n",
    "\n",
    "# check if index already exists \n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # if does not exist, create index\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=len(res['data'][0]['embedding']),\n",
    "        metric='cosine' # optional\n",
    "        # metadata_config={}\n",
    "    )\n",
    "# connect to index\n",
    "index = pinecone.GRPCIndex(index_name)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "upserted_count: 7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a list of embeddings to upsert\n",
    "to_upsert = []\n",
    "for i in range(len(res['data'])):\n",
    "    # make a tuple of (id, embedding)\n",
    "    chunk = (f\"id{i}\", res['data'][i]['embedding'], {\"text\": chunks[i]})\n",
    "    to_upsert.append(chunk)\n",
    "\n",
    "# upsert embeddings\n",
    "index.upsert(vectors=to_upsert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Apple Supplier Code of Conduct is a set of standards that suppliers must adhere to in order to do business with Apple. It covers topics such as labor and employment, anti-discrimination and anti-harassment, freedom of association, environmental protection, hazardous substances management, pollution prevention and resource sustainability, waste management, recycling, protection of intellectual property, and anti-corruption.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_with_context = retrieve(query)\n",
    "complete(query_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete index\n",
    "pinecone.delete_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
